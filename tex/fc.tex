\documentclass[a4paper, 11pt,titlepage, openright, twoside]{report}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{silence}
\usepackage{amsmath,amsfonts,amssymb,amsthm}
\usepackage{bm}
\usepackage{mathtools}
\usepackage[inline]{enumitem}
\usepackage{newunicodechar}
\usepackage[margin=3cm,bindingoffset=1cm]{geometry}
\usepackage{stmaryrd}
\SetSymbolFont{stmry}{bold}{U}{stmry}{m}{n}
% https://tex.stackexchange.com/a/106719
\DeclareSymbolFont{sfletters}{OML}{cmbrm}{m}{it}
\usepackage[nopatch=footnote]{microtype}
\usepackage[dvipsnames]{xcolor}
\usepackage{mathpartir}
\usepackage{biblatex}
%\usepackage{cleveref}
\usepackage{tikz}
\usepackage{tikz-cd}
\usepackage{listings}
\lstset{basicstyle=\ttfamily}

\usepackage[]{hyperref}
\usepackage[all]{hypcap}
\setlength{\parskip}{0pt}

\addbibresource{refs.bib}


\title{\textbf{A Fine Calculus for Static Delimited Control}}
\author{Wiktor Kuchta}

\date{100 września 2024} %TODO

\usepackage{titling}

\renewcommand \maketitlehookb {
  \begin{center}\large
  Fajny rachunek dla statycznie ograniczonych operatorów sterowania
  \end{center}
  \vfil
}

\renewcommand \maketitlehookc {
  \vfil
  \begin{center}
  \large Praca magisterska \\[0.85em]
  \begin{tabular}[t]{rl}
  \textbf{Promotor:} & dr hab.\ Dariusz Biernacki
  \end{tabular}\end{center}
  \vfil\vfil\vfil\vfil
  \begin{center}Uniwersytet Wroc\l{}awski\\
  Wydzia\l{} Matematyki i Informatyki\\
  Instytut Informatyki
  \end{center}
}

\newcommand{\Par}[1]{\stackrel{#1}{\Rrightarrow}}
\newcommand{\Rap}[1]{\stackrel{#1}{\Lleftarrow}}
\newcommand{\Int}{\Rightarrow}
\newcommand{\Tni}{\Leftarrow}
\newcommand{\Stan}{↦^* · \Int}
\newcommand{\foreign}[1]{#1}
\newcommand{\tagit}[1]{\tag{\textit{#1}}}
\newcommand{\tagmath}[1]{\tag{\(#1\)}}
\newcommand{\Log}{\textsf{log}}
\newcommand{\true}{\textsf{true}}
\newcommand{\false}{\textsf{false}}
\newcommand{\shiftz}{\textsf{shift0}}
\newcommand{\abort}{\textsf{abort}}
\newcommand{\keyword}[1]{\textsf{\textup{#1}}}
\newcommand{\KwOp}{\keyword{op}}
\newcommand{\Op}{\KwOp\,}
\newcommand{\KwHandle}{\keyword{handle}}
\newcommand{\Handle}{\KwHandle\;}
\newcommand{\KwWith}{\keyword{with}}
\newcommand{\With}{\;\KwWith\;}
\newcommand{\KwRaise}{\keyword{raise}}
\newcommand{\Raise}{\KwRaise\,}
\newcommand{\Ask}{\textsf{ask}}
\newcommand{\KwTry}{\keyword{try}}
\newcommand{\Try}{\KwTry\;}
\newcommand{\KwLet}{\keyword{let}}
\newcommand{\Let}[3]{\keyword{let}\:#1\:\keyword{=}\:#2\:\keyword{in}\:#3}
\newcommand{\Dlet}[3]{\keyword{dlet}\:#1\:\keyword{=}\:#2\:\keyword{in}\:#3}
\newcommand{\Letp}[3]{\keyword{let}^p\:#1\:\keyword{=}\:#2\:\keyword{in}\:#3}
\newcommand{\RLet}[3]{\Let{#1}{\raisebox{0.5 ex}{$#2$}}{#3}}
\newcommand{\Letrec}[3]{\keyword{letrec}\:#1\:\keyword{=}\:#2\:\keyword{in}\:#3}
\newcommand{\KwLift}{\keyword{lift}}
\newcommand{\Lift}[1]{\KwLift\;#1}
\newcommand{\subst}[2]{\{#1{:=}#2\}}
\newcommand{\E}{\mathcal{E}}
\newcommand{\K}{\mathcal{K}}
\renewcommand{\S}{\mathcal{S}}
\newcommand{\A}{\mathcal{A}}
\newcommand{\kT}{\mathsf{T}}
\newcommand{\kE}{\mathsf{E}}
\newcommand{\kR}{\mathsf{R}}
\newcommand{\Free}{\textrm{-}\mathrm{free}}
\newcommand{\Obs}{\mathrm{Obs}}
\newcommand{\N}{\mathbb{N}}
\DeclareMathOperator{\dom}{dom}
\newcommand{\+}{\enspace}
\newcommand{\lStr}{\textsf{Str}}
\newcommand{\lPar}{\textsf{Par}}

\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{prop}{Proposition}


\newunicodechar{≅}{\cong}
\newunicodechar{│}{\mid} % Digr vv
\newunicodechar{╱}{\bm{/}} % Digr FD
\newunicodechar{∷}{::} % Digr ::
\newunicodechar{□}{\square} % Digr OS
\newunicodechar{∅}{\emptyset} % Digr /0
\newunicodechar{α}{\alpha}
\newunicodechar{β}{\beta}
\newunicodechar{δ}{\delta} % Digr d*
\newunicodechar{ε}{\varepsilon}
\newunicodechar{γ}{\gamma} % Digr g*
\newunicodechar{ι}{\iota} % Digr i*
\newunicodechar{κ}{\kappa}
\newunicodechar{λ}{\lambda}
\newunicodechar{μ}{\mu}
\newunicodechar{ν}{\nu}
\newunicodechar{ρ}{\rho}
\newunicodechar{σ}{\sigma}
\newunicodechar{τ}{\tau}
\newunicodechar{η}{\eta} % Digr y*
\newunicodechar{Δ}{\Delta}
\newunicodechar{Γ}{\Gamma}
\newunicodechar{Ω}{\Omega} % digr W*
\newunicodechar{ℕ}{\N} % Digr NN 8469 nonstandard
\newunicodechar{⊆}{\subseteq} % Digr (_
\newunicodechar{∪}{\cup} % Digr )U
\newunicodechar{∈}{\in} % Digr (-
\newunicodechar{∃}{\exists} % Digr TE
\newunicodechar{∀}{\forall} % Digr FA
\newunicodechar{∧}{\wedge} % Digr AN
\newunicodechar{∨}{\vee} % Digr OR
\newunicodechar{⊥}{\bot} % Digr -T
\newunicodechar{⊢}{\vdash} % Digr \- 8866 nonstandard
\newunicodechar{⊨}{\models} % Digr \= 8872 nonstandard
\newunicodechar{⊤}{\top} % Digr TO 8868 nonstandard
\newunicodechar{⇒}{\implies} % Digr =>
\newunicodechar{⇔}{\iff} % Digr ==
\newunicodechar{↦}{\mapsto} % Digr T> 8614 nonstandard
\newunicodechar{≠}{\neq}
\newunicodechar{⟦}{\bm{[}}
\newunicodechar{⟧}{\bm{]}}
\newunicodechar{≥}{\ge}
\newunicodechar{≤}{\le}
\newunicodechar{≡}{\equiv}
\newunicodechar{≈}{\approx}


% cursed
\WarningFilter{newunicodechar}{Redefining Unicode}
\newunicodechar{·}{\ifmmode\cdot\else\textperiodcentered\fi} % Digr .M
\newunicodechar{×}{\ifmmode\times\else\texttimes\fi} % Digr *X
\newunicodechar{→}{\ifmmode\rightarrow\else\textrightarrow\fi} % Digr ->
\newunicodechar{←}{\ifmmode\leftarrow\else\textleftarrow\fi} % Digr <-
\newunicodechar{…}{\ifmmode\dots\else\textellipsis\fi} % Digr .,
\newunicodechar{⟨}{\bm{\langle}}
\newunicodechar{⟩}{\bm{\rangle}}
\newunicodechar{¦}{\bm{│}}

\begin{document}

\maketitle


\thispagestyle{empty}
\cleardoublepage
\begin{abstract}
	We consider a variant of the call-by-value $λμ$-calculus extended with control delimiters,
	in which $μ$ becomes the static delimited control operator $\shiftz$.
	We propose new reduction rules for cases where the captured continuation can be determined statically.
	We let delimiters carry data (resulting in a form of dynamic binding), which lets us express deep effect handlers.
	We prove the reductions semantics-preserving and partially confluent,
	verified in the Abella proof assistant.
	We argue that the calculus is stronger than previous results in the literature and could form basis for
	reasoning and optimizations for the aforementioned forms of control.
%
	\begin{center} \rule[3pt]{300pt}{1pt} \end{center}
%
	Rozważamy wariant rachunku $λμ$ z wołaniem przez wartość rozszerzony
	o ograniczniki,
	tworząc z $μ$ statycznie ograniczony operator sterowania $\shiftz$.
	Proponujemy nowe reguły redukcji dla sytuacji,
	w których przechwycona kontynuacja może być statycznie wyznaczona.
	Rozszerzamy ograniczniki pozwalając im trzymać dane
	(dając swego rodzaju wiązanie dynamiczne),
	co pozwala nam wyrazić obsługę efektów.
	Dowodzimy, że redukcje zachowują semantykę i są częściowo konfluentne,
	co też zweryfikowaliśmy w asystencie dowodzenia Abella.
	Argumentujemy, że powstały rachunek jest mocniejszy niż poprzednie wyniki w literaturze
	i mógłby stanowić podstawę dla wnioskowania i optymalizacji dla wspomnianych operatorów sterowania.

\end{abstract}


\thispagestyle{empty}
\cleardoublepage
\setcounter{page}{5}
\tableofcontents


\chapter{Introduction}
Consider a program of the following form in a language with (unnamed) exceptions:
\begin{align*}
	&\Try \\
	&\quad \Let{y}{\textit{expr}}{\Raise (y*2)} \\
	&\KwWith\; x.\,x*3
\end{align*}
If the execution gets to $\Raise (y*2)$, the handler will catch the exception and produce the result $y*2*3$.
How to \textit{optimize} the program, so that we only perform one multiplication, $y*6$?

We can ask the same question for \textit{effect handlers}.
This generalization allows us to capture the \textit{continuation} of the \textit{operation} (a.k.a.\,\textit{generic effect}) we are handling
and bind it as a variable.
The conventional evaluation step rule is:
$$\Handle E[\Op v] \With x\;k.\,e ↦  e\subst{x}{v}\subst{k}{λz.\,\Handle E[z] \With x\;k.\,e} $$
This is a form of \textit{static delimited control}:
\textit{control} refers to capture of continuations
(represented using \textit{evaluation contexts} $E$),
\textit{delimited} to them being delimited by the handler,
and \textit{static} to the delimiter staying in the captured continuation.

Here's a similar example:
$$ \Handle \Let{y}{e}{\Op (y*2)} \With x\;k.\,k\,(x*3) $$
Just as in the example of exceptions, we know that $\Op (y*2)$ will be handled
by the $x\;k.\,k\,(x*3)$ handler---%
even if continuation capture occurs during the execution of expression $e$,
the $\KwOp$ and the $\KwHandle$ will stay together.

We therefore know the substitution that will be performed during the handling of the operation:
$x:=y*2$.
Exactly this substitution is needed to rewrite the two multiplications into one.
We also can deduce the substitution $k:=λz.\,\Handle z \With x\;k.\,k\,(x*3)$.
But where to substitute?
Certainly not in the handler's clause,
because the clause could be used for different operations inside $e$,
and $y$ is not even in scope.

Since we know the clause that will run for the specific operation,
instead of performing the operation
we could \textit{abort} the handler and execute the clause specialized with the specific substitutions.
That is, rewrite the $\Op (y*2)$ into:
$$\abort\,(k\,(x*3))\subst{x}{y*2}\subst{k}{λz.\,\Handle z \With x\;k.\,k\,(x*3)}$$
After some simplification we obtain:
$$\Handle \Let{y}{e}{\abort\,(y*6)} \With x\;k.\,k\,(x*3)$$

\noindent{}
\hrulefill

\noindent{}
The preceding whirlwind development may raise some questions.
\begin{enumerate}
	\item Is it even correct?
	\item Where does the $\abort$ come from? (And what does it mean?)
	\item Will the optimization rule fit on the page, if the evaluation one almost didn't?
\end{enumerate}
We will try to address them.

The issue with conventional syntax for operations and effect handlers is that
the operations are \textit{passive}.
In a real implementation, when we get to an operation, we immediately begin the search for a handler.
The syntax does not reflect that, it doesn't say what happens next. It's just an operation name and a payload value.

We will therefore base our calculus for optimizations on the other static delimited control operator:
$\shiftz$. The conventional rule for $\shiftz$ and its delimiter \textsf{reset} (written $⟨·⟩$) is:
$$⟨E[\shiftz\,k.\,e]⟩ ↦ e\subst{k}{λy.\,⟨E[y]⟩}$$
Here, the $\shiftz$ assumes the active role by initiating capture of continuation $k$ and carrying the expression $e$ that says what to do with it,
while the delimiter is passive---it merely delimits.
We can now express \abort{} simply as a $\shiftz$ that ignores the continuation: $\textsf{abort}\,e ≡ \shiftz\,\_.\,e$.

To express effect handlers, we will extend delimiters by letting them carry a value.
The value will be a lambda abstraction $λx\,k.\,e$ representing the handler's clause.
An operation will be a $\shiftz$ that explicitly asks for it and passes the payload and continuation.
So, the $\abort$ arises as a result of substitution for $k$ in the $\shiftz$'s body.

Finally, to achieve fine-grained steps instead of complex rules that shuffle entire contexts around,
we will get rid of the irregularity that is the $λ$-abstraction wrapping the continuation.
Delimited continuations will not be represented as call-by-value functions, but instead
as their own sort with the ability to plug in any expression, not just a value.
This lets us use structural substitution known from the $λμ$-calculus and all the benefits it brings \cite{benefit}.

\chapter{Syntax}
\label{Syntax}

\begin{figure}
\begin{align*}
	\text{(value) variables} &&x,y,... \\
	\text{continuation variables} && κ \\
	\text{values} &&v,u &::= x │ λx.\,e │ \Ask(κ) \\
	\text{expressions} &&e,t &::= v │ v\:v │ \Let{x}{e}{t} │ \S κ.\,e │ ⟨e ╱ v⟩ │ κ⟦e⟧  \\
	\text{evaluation contexts}&&E   &::= □ │ \Let{x}{E}{t} \\
	\text{tail contexts}&&L &::= □ │ \Let{x}{e}{L} \\
	\text{delim.\ continuations}&&D &::= ⟨E╱v⟩ │ κ⟦E⟧ \\
	\text{metacontinuations}&&K   &::= □ │ \Let{x}{K}{t} │ κ⟦K⟧ │ ⟨K╱v⟩
\end{align*}
\caption{Syntax.}
\label{syntax}
\end{figure}
\begin{figure}
\begin{align*}
	(λx.\,e)\:v &↦ e\subst{x}{v} \\
	\Let{x}{v}{t} &↦ t\subst{x}{v} \\
	⟨v╱u⟩ &↦ v \\
	D[\S κ'.\,e] &↦ e\subst{κ'}{D}
\end{align*}
\caption{Evaluation step.}
	\label{step}
\end{figure}
\begin{figure}
	\begin{align*}
		λx\,y.\,e &≡ λx.\,λy.\,e \tag{multi-param lambda} \\
		e_1\:e_2 &≡ \Let{x}{e_1}{\Let{y}{e_2}{x\,y}} \tag{left-to-right application}\\
		\A\,e ≡ \abort\,e&≡ \S \_.\,e \tag{abort}\\
		⟨e⟩ &≡ ⟨e╱λx.\,x⟩ \tag{reset with dummy value}\\
		\shiftz\,k.\,e &≡ \S κ.\,\Let{k}{λx.\,κ⟦x⟧}{e} \tag{value-binding shift0}\\
		⟨e¦y.\,t_r⟩ &≡ ⟨\Let{y}{e}{\A\,t_r}⟩ \tag{reset with return clause} \\
		\Op v &≡ \S κ.\,\Ask(κ)\:v\:(λx.\,κ⟦x⟧) \tag{operation/generic effect}\\
		\Handle e \With x\,k.\,t &≡ ⟨e╱λx\,k.\,t⟩ \tag{effect handler}\\
		\Handle e \With x\,k.\,t ¦ y.\,t_r &≡ ⟨\Let{y}{e}{\A\,t_r}╱λx\,k.\,t⟩ \tag{handler w/ return clause}\\
	\end{align*}
	\caption{Shorthands (macro-expressions).}
	\label{shorthands}
\end{figure}
\begin{figure}
	\begin{align*}
		(λx.\,e)\,v &→ e\subst{x}{v} \tagmath{λ.v} \\
		\Let{x}{v}{t} &→ t\subst{x}{v} \tagmath{\KwLet{}.v} \\
		⟨v╱u⟩ &→ v \tagmath{d.v} \\
		\Let{x}{\S κ.\,e}{t} &→ \S κ.\,e\subst{κ}{κ⟦\Let{x}{□}{t}⟧} \tagmath{\KwLet{}.\S} \\
		⟨\S κ.\,e ╱ v⟩ &→ e\subst{κ}{⟨□╱v⟩} \tagmath{d.\S} \\
		κ⟦\S κ'.\,e⟧ &→ e\subst{κ'}{κ} \tagmath{k.\S} \\
		⟨L[\S κ.\,e]╱v⟩ &→ ⟨L[A\,e\subst{κ}{⟨□╱v⟩}]╱v⟩ \tagmath{dL.\S} \\
		⟨L[\A⟨e╱v⟩]╱v⟩ &→ ⟨L[e]╱v⟩ \tagmath{\A.d} \\
		⟨L[\A\,u]╱v⟩ &→ ⟨L[u]╱v⟩ \tagmath{\A.v} \\
		\Let{x}{\Let{y}{e}{t_1}}{t_2} &→ \Let{y}{e}{\Let{x}{t_1}{t_2}} \tagmath{\KwLet{}.\KwLet{}}
	\end{align*}
	\caption{Reduction.}
	\label{reduction}
\end{figure}


The grammar of the calculus is in figure \ref{syntax}.
We base it on a fine-grained call-by-value $λ$-calculus,
meaning that the subterms of application $v\:u$ are values
and computations have to be sequenced with $\KwLet$.
The expression $\S κ.\,e$ captures the delimited continuation as $κ$,
a generalization of $\shiftz$.\footnote{
$\S$ is similar to $μ$ in the $λμ$-calculus.
}
The \textit{reset} or \textit{delimiter} $⟨e╱v⟩$ delimits continuations captured in $e$ and carries a value $v$.
The \textit{plug} construct $κ⟦e⟧$ installs continuation $κ$ and resumes with execution of $e$.%
\footnote{
The $λμ$-calculus conventionally uses the notation $⟦κ⟧e$, but we abandon it
as it's inconsistent with the common metanotation of plugging an expression into a context.
}
The value $\Ask (κ)$ refers to the value carried by the delimiter which delimited $κ$.

Contexts are expressions with a hole ($□$), with $C[e]$ denoting substituting (or plugging)
the expression $e$ for the hole in $C$.
In general, this is variable-capturing substitution,
but not for metacontinuations $K$ since they don't bind variables.
We can also plug a context into a context, as in $C[C']$,
to form another context.
Metacontinuations $K$ use the $□$ to mark the \textit{evaluation position},
whereas tail contexts $L$ mark the \textit{tail position}.
Intuitively, they are the first and the last places where execution occurs.
We will refer to metacontinuation formers as \textit{frames}.
Every $E$ or $D$ is a $K$, so previous statements apply analogously.

\section{Structural substitution}

We will be using the notions of
substitution for variables ($e\subst{x}{v}$)
and substitution for continuation variables ($e\subst{κ}{D}$),
the latter of which requires some explaining.
It suffices to consider the two expression formers that use $κ$:
\begin{enumerate}
	\item
		$κ⟦e⟧\subst{κ}{D} ≡ D[e\subst{κ}{D}]$ \\
		On the left, the brackets are on the object level, while on the right they
		denote plugging the expression $e\subst{κ}{D}$ into context $D$ on the meta level.
%		This justifies the punning – one can see the $κ⟦e⟧$ as the point where
%		the meta-operation of plugging gets stuck, a normal form.
	\item
		$\Ask(κ)\subst{κ}{⟨E╱v⟩} ≡ v$ \\
		$\Ask(κ)\subst{κ}{κ'⟦E⟧} ≡ \Ask(κ')$
\end{enumerate}
As further illustration, 
here are the three forms of structural substitution used in reduction (figure \ref{reduction}):
\begin{align*}
	κ⟦e⟧\subst{κ}{κ'} &≡ κ'⟦e\subst{κ}{κ'}⟧ \\
	\Ask(κ)\subst{κ}{κ'} &≡ \Ask(κ') \\
	κ⟦e⟧\subst{κ}{κ⟦\Let{x}{□}{t}⟧} &≡ κ⟦\Let{x}{e\subst{κ}{κ⟦\Let{x}{□}{t}⟧}}{t}⟧ \\
	\Ask(κ)\subst{κ}{κ⟦\Let{x}{□}{t}⟧} &≡ \Ask(κ) \\
	κ⟦e⟧\subst{κ}{⟨□╱v⟩} &≡ ⟨e\subst{κ}{⟨□╱v⟩}╱v⟩ \\
	\Ask(κ)\subst{κ}{⟨□╱v⟩} &≡ v
\end{align*}

\section{Evaluation steps}

The evaluation step relation $↦$ is taken to be the closure of rules in figure \ref{step}
under metacontinuations.
The first two rules are standard beta reductions.
The third rule pops the delimiter once computation inside is finished.
The fourth one is responsible for capturing the delimited continuation
when an $\S$ is in evaluation position.
To an extent we accommodate open evaluation,
namely evaluating under continuation variables and capturing of continuation variables.

We could have opted for fine-grained evaluation steps,
those would be exactly the first six reduction rules (figure \ref{reduction}).
We have taken the coarse-grained steps as the operational semantics because
this greatly simplifies adequacy and it's closer in spirit to machine implementations.

We haven't formalized an abstract machine, but we will be referring to the intuitions that
metacontinuations correspond to machine stacks and $\S$ captures the stack up to the closest reset frame.

\section{Shorthands}
We will be using the shorthands in figure \ref{shorthands}.
The first two of them are commonly used for convenience.
The third one introduces the notation $\A$ for $\abort$.
The fourth one lets us omit data in delimiters ($╱v$) when irrelevant.
Then, we have macros that formally justify that the calculus can express the relevant
control operators in their standard form.
It is easy to check that evaluation steps simulate the standard evaluation rules for the simulated constructs,
we write out some examples for $\shiftz$ and effect handlers.
\begin{align*}
	⟨E[\shiftz\,k.\,e]⟩
	&≡ ⟨E[\S κ.\,\Let{k}{λx.\,κ⟦x⟧}{e}]⟩ \\
	&↦ \Let{k}{λx.\,⟨E[x]⟩}{e} \\
	&↦ e\subst{k}{λx.\,⟨E[x]⟩} \\
\\
	\Handle E[\Op v] \With x\,k.\,t
	&≡ ⟨E[\S κ.\,\Ask(κ)\:v\:(λx.\,κ⟦x⟧)]╱λx\,k.\,t⟩ \\
	&↦ (λx\,k.\,t)\:v\:(λx.\,⟨E[x]╱λx\,k.\,t⟩) \\
%	&↦ (λk.\,t\subst{x}{v})\:(λx.\,⟨E[x]╱λx\,k.\,t⟩) \\
	&↦^* t\subst{x}{v}\subst{k}{λx.\,⟨E[x]╱λx\,k.\,t⟩} \\
	&≡ t\subst{x}{v}\subst{k}{λx.\,\Handle E[x] \With x\,k.\,t} \\
\\
	\Handle v \With x\,k.\,t_h ¦ y.\,t_r
	&≡ ⟨\Let{y}{v}{\A\,t_r}╱λx\,k.\,t_h⟩ \\
	&↦ ⟨\A\,t_r\subst{y}{v}╱λx\,k.\,t_h⟩ \\
	&↦ t_r\subst{y}{v}
\end{align*}

The last calculation above features a handler with a \textit{return clause}.
The return clause extends the delimited continuation
with a fragment that doesn't run inside the delimiter.
The same extension is possible for reset, there often called \textit{dollar}.
In previous work it has always been an integral part of syntax,
we notice that it can be easily expressed as a $\KwLet$ frame that aborts the delimiter.

\section{Reduction}
\label{secreduction}
We define reduction $→$ to be the closure of rules in figure \ref{reduction}
under general contexts.
In this section we will demonstrate how reduction in the calculus
can be used for optimization.
We may assume common features such as arithmetic for presentation purposes.

%The first few rules are shared with evaluation, now we can use them for simplifications anywhere in the expression.

\subsection{Structural reduction}
\label{strred}

The rule $\KwLet{}.\S$ has utility beyond taking apart the context $E$ when finely simulating the
evaluation rule for continuation capture.
Consider the following snippet:
$$ \Let{x}{\S κ.\,κ⟦40⟧}{x+2} → \S κ.\,κ⟦\Let{x}{40}{x+2}⟧ → \S κ.\,κ⟦40+2⟧ → \S κ.\,κ⟦42⟧$$
There is no delimiter to find for the $\S$, but we do know a prefix of the continuation
that $\S$ may capture, and we can put this knowledge to good use.

The above example also shows the power of the $κ⟦e⟧$ expression former.
We can consider a similar example with the value-capturing $\shiftz$ syntax:
$$\Let{x}{\shiftz\,k.\,k\,40}{f\,x}$$
If $\shiftz$ captures the continuation, $f$ will be applied to $40$, but there is nothing we can do with that knowledge in this syntax.
A naïve attempt would be:
$$\shiftz\,k.\, k\,(f\,40)$$
But this is incorrect: $f\,40$ won't run inside the captured continuation, it will be evaluated separately and
then the result will be passed to $k$.
This changes the behavior if $f$ also uses $\shiftz$.

The rule $d.\S$ deals with the easy case where an $\S$ is in direct contact with a delimiter.
The rule $k.\S$, \textit{renaming} in $λμ$-parlance, is more interesting,
since it doesn't have a counterpart within the conventional
continuation-as-lambda syntax.
Consider a code fragment with consecutive uses of effects:
\begin{align*}
	\Let{\_}{\Op 0}{\Op 1}
	&≡ \Let{\_}{\S κ.\,\Ask(κ)\,0\,(λy.\,κ⟦y⟧)}{\S κ.\,\Ask(κ)\,1\,(λz.\,κ⟦z⟧)} & \\
	&→ \S κ.\,\Ask(κ)\,0\,\big(λy.\,κ⟦\Let{\_}{y}{\S κ.\,\Ask(κ)\,1\,(λz.\,κ⟦z⟧)}⟧\big) \tagmath{\KwLet{}.\S} \\
	&→ \S κ.\,\Ask(κ)\,0\,\big(λ\_.\,κ⟦\S κ.\,\Ask(κ)\,1\,(λz.\,κ⟦z⟧)⟧\big) \tagmath{\KwLet{}.v} \\
	&→ \S κ.\,\Ask(κ)\,0\,\big(λ\_.\,\Ask(κ)\,1\,(λz.\,κ⟦z⟧)\big) \tagmath{k.\S}
\end{align*}
We have completely eliminated the second control operation,
drawing on the fact that both of them will reach the same handler.

There are other natural uses of the plug construct $κ⟦e⟧$.
For example, in OCaml 5, delimited continuations are clearly not functions, since
we can not only \textit{continue} them (apply to a value), but also \textit{discontinue} them: raise an exception inside.
This is trivial to express with plug: $\textsf{discontinue}\,κ\,\textit{exn} ≡ κ⟦\textsf{raise}\,\textit{exn}⟧$.
%whereas previous formalizations have used workarounds with lambda abstractions.

\subsection{Capturing the static delimiter out of order}

The rule $dL.\S$ says that an $\S$ in the tail position of a delimiter
will capture that delimiter (if we get to it).
This is thanks to being in the setting of \textit{static} delimited control.
The rule is obviously infinitely-looping,
but we can prevent that with a side condition that $κ$ actually occurs in $e$.
The rewrite is \textit{at a distance}, as the pattern involves a context $L$.
We believe the rule still deserves to be called fine-grained,
as the outer context $⟨L╱v⟩$ remains intact.

We will try to convey the intuition why it's correct by considering the case
where $L$ is just one $\KwLet$ expression: $L ≡ \Let{x}{e}{□}$.
If $e$ evaluates to a value, then the $\S$ will capture the delimiter:
\begin{align*}
	⟨\Let{x}{v}{\S κ.\,t}⟩ ↦ ⟨\S κ.\,t\subst{x}{v}⟩ ↦ t\subst{x}{v}\subst{κ}{⟨□⟩}
\end{align*}
If continuation capture occurs inside $e$,
then the focused $\S$ will still be in the tail position
of the delimiter, now captured. Loosely speaking, we can reason recursively.%
\footnote{
	Perhaps this idea could be formalized as (co)induction on some form of interaction tree,
	with $e$ evaluating to a value as leaves and continuation capture
	resulting in a branch for every expression plugged.
}
\begin{align*}
	⟨\Let{x}{E[\S κ'.\,e']}{\S κ.\,t}⟩ ↦ e'\subst{κ'}{⟨\Let{x}{E}{\S κ.\,t}⟩}
\end{align*}
If the $e$ never evaluates to a value, then the rule rewrites dead code, which is fine.

\begin{figure}
\begin{align*}
&\Handle \Log\,();\Let{x}{\Op()}{\Let{y}{\Op()}{f(x,y)}} \With x\,k.\,k\,\true ││ k\,\false \\
≡\enspace &⟨\Log\,();\Let{x}{\Op()}{\Let{y}{\Op()}{f(x,y)}} ╱ h ⟩ \\
→\enspace &⟨\Log\,();\S κ.\,\Ask(κ)\,()\,(λz.\,κ⟦\Let{x}{z}{\Let{y}{\Op()}{f(x,y)}}⟧) ╱ h ⟩ \tagmath{\KwLet{}.\S} \\
→\enspace &⟨\Log\,();\S κ.\,\Ask(κ)\,()\,(λz.\,κ⟦\Let{y}{\Op()}{f(z,y)}⟧) ╱ h ⟩ \tagmath{\KwLet{}.v} \\
→\enspace &⟨\Log\,();\A\,h\,()\,(λz.\,⟨\Let{y}{\Op()}{f(z,y)}╱h⟩) ╱ h ⟩ \tagmath{dL.\S} \\
→^*\enspace &⟨\Log\,();\A\,⟨\Let{y}{\Op()}{f(\true,y)}╱h⟩ \\
& \quad\quad\quad ││ ⟨\Let{y}{\Op()}{f(\false,y)}╱h⟩ ╱ h ⟩ \tagmath{λ.v, \KwLet{}.v} \\
→^*\enspace & ⟨\Log\,();\A\,\big(h\,()\,(λz.\,⟨\Let{y}{z}{f(\true,y)}/h⟩)\big) \\
& \quad\quad\quad ││ \big(h\,()\,(λz.\, ⟨\Let{y}{z}{f(\false,y)}/h⟩)\big) ╱ h⟩ \tagmath{\KwLet{}.\S, d.\S} \\
→^*\enspace & ⟨\Log\,();\A\,\big(⟨f(\true,\true))/h⟩ ││ ⟨{f(\true,\false)})/h⟩\big) \\
& \quad\quad\quad ││ \big(⟨f(\false,\true)/h⟩ ││ ⟨f(\false,\false)/h⟩\big) ╱ h⟩ \tagmath{λ.v, \KwLet{}.v}
\end{align*}
\caption{
	A program for checking satisfiability of a Boolean function $f$.
	When the operation asks for a boolean,
	the handler
	$h ≡ λx\,k.\,k\,\true ││ k\,\false$
	tries both options and takes the logical OR, simulating angelic nondeterminism.
	We use the shorthand $e_1;e_2 ≡ \Let{\_}{e_1}{e_2}$ for sequencing expressions.
	Think of $\textit{log}$ as some function with side effects,
	its purpose in the example is to prevent
	the first $\KwOp$ from being in evaluation position.
}
\label{sat}
\end{figure}

For an extended illustration of how reduction transforms programs,
see figure \ref{sat}.
Proceeding similarly as in it,
we can finally derive the coarse-grained rewrites that started it all:
$$⟨L[E[\shiftz\,k.\,e]]⟩ →^* ⟨L[\abort\,e\subst{k}{λz.\,⟨E[z]⟩}]⟩$$
The one for statically handling effects indeed won't fit on one line:
\begin{alignat*}{2}
	&\Handle L[E[\Op v]{}&] \With x\,k.\,t \\
	→^* \enspace &\Handle L[\abort\,t\subst{x}{v}\subst{k}{λz.\,\Handle E[z] \With x\,k.\,t}{}&] \With x\,k.\,t
\end{alignat*}


\subsection{Eta-like reductions}

Inspired by the $λμ$-calculus, we could consider an $η$-reduction of the following form:
$$\S κ.\,κ⟦e⟧ → e$$
In words, capturing a continuation and then immediately installing it
amounts to doing nothing.
However, the rewrite changes program behavior if the program originally got stuck on searching for a delimiter.
We therefore perform the reduction in tail-of-reset contexts to ensure this doesn't happen.
The resulting rule $\A.d$ can be of a slightly simplified form,
since the $dL.\S$ reduction always applies:
$$⟨L[\S κ.\,κ⟦e⟧]⟩ → ⟨L[\A⟨e\subst{κ}{⟨□⟩}⟩]⟩$$

The $\A.v$ rule is explained thus: in the tail position of a delimiter,
aborting and returning a value amounts to the same as simply returning a value,
since a delimiter is popped anyway if the inside computation finished with a value.
It is necessary for confluence, specifically to complete this peak:
$$⟨L[\A\,v]⟩ \xleftarrow{d.v} ⟨L[\A⟨v⟩]⟩ \xrightarrow{\A.d} ⟨L[v]⟩$$

A common pattern where a captured continuation is immediately resumed is
the \textit{reader} effect,
where an operation (with no payload) asks for a value and the handler provides it:
\begin{align*}
	\Handle e \With \_\,k.\,k\,v
\end{align*}
The reader effect simulates dynamic binding,
with the operation taking the role of reference to a (nameless) parameter and the handler taking the role of the binder.

In general, we don't need to adhere to the protocol that the value carried in the delimiter
is the clause of an effect handler.
We can accomplish the same in a simpler way by putting the dynamically bound value directly
as the data in the delimiter.
To obtain the value in the delimiter we simply do $\textsf{ask} ≡ \S κ.\,κ⟦\Ask(κ)⟧$.
The reduction rules let us replace the $\textsf{ask}$ with the correct value
if it can be statically determined:
\begin{align*}
	⟨\Let{x}{e}{\Let{y}{\textsf{ask}}{t}}╱v⟩
	&≡ ⟨\Let{x}{e}{\Let{y}{\S κ.\,κ⟦\Ask(κ)⟧}{t}}╱v⟩ \\
	&→ ⟨\Let{x}{e}{\S κ.\,κ⟦\Let{y}{\Ask(κ)}{t}⟧}╱v⟩ \tagmath{\KwLet{}.\S} \\
	&→ ⟨\Let{x}{e}{\A\,⟨\Let{y}{v}{t}╱v⟩}╱v⟩ \tagmath{dL.\S} \\
	&→ ⟨\Let{x}{e}{\Let{y}{v}{t}}╱v⟩ \tagmath{\A.d}
\end{align*}
Naturally, the same applies to the effect handler approach.

\subsection{Let reassociation}

The purpose of let reassociation ($\KwLet{}.\KwLet{}$) is to unblock other reductions.
It is one of the ways to obtain a richer theory of open call-by-value \cite{open}.
%Preventing premature $β$-normal forms is one of the ways to obtain a richer theory of open call-by-value \cite{open}:
\begin{align*}
\Let{x}{\Let{y}{e}{v}}{t}
&→ \Let{y}{e}{\Let{x}{v}{t}} \tagmath{\KwLet{}.\KwLet{}} \\
&→ \Let{y}{e}{t\subst{x}{v}} \tagmath{\KwLet{}.v}
\end{align*}
For this work, it's especially useful to unblock the $\KwLet{}.\S$ and tail-of-reset reductions:
\begin{align*}
⟨\Let{x}{\Let{y}{e}{\S κ.\,e}}{t}⟩
&→ ⟨\Let{y}{e}{\Let{x}{\S κ.\,e}{t}}⟩ \tagmath{\KwLet{}.\KwLet{}} \\
&→ ⟨\Let{y}{e}{\S κ.\,e\subst{κ}{κ⟦\Let{x}{□}{t}⟧}}⟩ \tagmath{\KwLet{}.\S} \\
&→ ⟨\Let{y}{e}{\A \,e\subst{κ}{⟨\Let{x}{□}{t}⟩}}⟩ \tagmath{dL.\S}
\end{align*}
More abstractly, it commutes evaluation and tail contexts:
$$E[L] →^* L[E]$$
In this way, it improves applicability of the coarse-grained reductions derived previously:
we can statically handle any effect separated from the handler only by $\KwLet$ expressions.


\chapter{Adequacy}

The previous chapter has demonstrated how reduction can be used for optimization.
Now we have to show that it doesn't change the result of a program.

\section{Internal parallel reduction and standard reduction}
In studying interplay of evaluation and reduction,
it will be useful to isolate reductions that are \textit{not} evaluation steps: \textit{internal} reductions.
Furthermore, in later inductive arguments it will be useful that rewrite steps do not multiply.
To this end, we will define \textit{internal parallel reduction} $\Int$ (figure \ref{internal}),
which can perform reductions in many places of the term at once.
This lets us define \textit{standard} reduction as the composition of many evaluation steps and
an internal parallel reduction: $↦^* · \Int$.

\begin{figure}
\begin{mathpar}
	\inferrule{}
	{x \Int x}

	\inferrule{}
	{\Ask(κ) \Int \Ask(κ)}

	\inferrule{e \Stan e'}
	{λx.\,e \Int λx.\,e'}

	\inferrule{}
	{□ \Int □}

	\inferrule{v \Int v' \\ u \Int u'}
	{v\:u \Int v'\:u'}

	\inferrule{e \Int e' \\ t \Stan t'}
	{\Let{x}{e}{t} \Int \Let{x}{e'}{t'}}

	\inferrule{e \Stan e'}
	{\S κ.\,e \Int \S κ.\,e'}

	\inferrule{e \Int e' \\ v \Int v'}
	{⟨e╱v⟩ \Int ⟨e'╱v'⟩}

	\inferrule{e \Int e'}
	{κ⟦e⟧ \Int κ⟦e'⟧}

	\inferrule{e \Stan e' \\ t \Stan t'}
	{\Let{x}{\S κ.\,e}{t} \Int \S κ.\,e'\subst{κ}{κ⟦\Let{x}{□}{t'}⟧}}

	\inferrule{e \Int e' \\ t_1 \Stan t_1' \\ t_2 \Stan t_2'}
	{\Let{x}{\Let{y}{e}{t_1}}{t_2} \Int \Let{y}{e'}{\Let{x}{t_1'}{t_2'}}}

	\inferrule{L \Int L' \\ e \Stan e' \\ v \Int v' }
	{⟨L[\S κ.\,e]╱v⟩ \Int ⟨L'[\A\,e'\subst{κ}{⟨□╱v'⟩}]╱v'⟩}

	\inferrule{L \Int L' \\ e \Stan e' \\ v \Int v' }
	{⟨L[\A\,⟨e╱v⟩]╱v⟩ \Int ⟨L'[e']╱v'⟩}

	\inferrule{L \Int L' \\ v \Int v' \\ u \Int u' }
	{⟨L[\A\,u]╱v⟩ \Int ⟨L'[u']╱v'⟩}
\end{mathpar}
\caption{Internal parallel reduction.}
\label{internal}
\end{figure}


\begin{lemma}[Reflexivity]
	$e \Int e$
\end{lemma}

\begin{lemma}
	${→} ⊆ {↦^* · \Int} ⊆ {→^*}$
\end{lemma}

\begin{lemma} Assume $e \Int e'$. Then $e$ is a value iff $e'$ is a value.
\end{lemma}

\begin{lemma}[Substitution]
	\item
	\begin{enumerate}
		\item If $e \Int e'$ and $v \Int v'$, then $e\subst{x}{v} \Int e'\subst{x}{v'}$;
		\item If $e \Int e'$ and $D \Int D'$, then $e\subst{κ}{D} \Int e'\subst{κ}{D'}$.
	\end{enumerate}
\end{lemma}


\section{Postponement}

\begin{theorem}[Strong postponement]
	$${\Int · ↦} ⊆ {↦^* · \Int}$$
\end{theorem}
\begin{proof}
	By induction on $\Int$ and cases.
\end{proof}
\begin{corollary}
	${\Int · ↦^*} ⊆ {↦^* · \Int}$
\end{corollary}
\begin{proof}
	Induction on the length of $↦^*$.
\end{proof}
\begin{corollary}[Adequacy 1]
	If $e → e'$ and $e'$ evals to a value, then $e$ evals to a value.
\end{corollary}

We can derive (but don't need) semi-standardization and factorization:
$$→^* = (↦ ∪ \Int)^* ⊆ {↦^* · \Int^*}$$

\section{Commutation}

\begin{theorem}
 \label{quasisubcomm}
	$${\Tni · ↦ } ⊆ {↦^= · \Tni · \mapsfrom^*}$$
\end{theorem}
\begin{proof}
	By induction on $\Tni$ and cases.
\end{proof}
The reflexive closure of $↦$ ($↦^=$, or $≤1$ step of $↦$) appears because of the case
where $\A.d$ and $↦$ do the same thing: $⟨\A⟨e⟩⟩$.

\begin{corollary}[Subcommutation]
	${(\Tni · \mapsfrom^*) · ↦} ⊆ {↦^= \mathbin{·} ({{\Tni} · \mapsfrom^*})}$
\end{corollary}
\begin{proof}
	From the theorem % ${\Tni · ↦ } ⊆ {↦^= · \Tni · \mapsfrom^*}$
	and
	${(\Tni · \mapsfrom^+) · ↦} ⊆ {{{\Tni} · \mapsfrom^*}}$ (by determinism of $↦$).
\end{proof}
\begin{corollary}
	${(\Tni · \mapsfrom^*) · ↦^*} ⊆ {↦^* \mathbin{·} ({{\Tni} · \mapsfrom^*})}$
\end{corollary}
\begin{proof}
	Induction on the length of $↦^*$.
\end{proof}
\begin{corollary}[Adequacy 2]
	If $e → e'$ and $e$ evals to a value, then $e'$ evals to a value.
\end{corollary}

We can derive (but don't need) the full property of commutation of $→$ and $↦$:
$${←^* · ↦^*} ⊆ {↦^* · ←^*}$$
Usually, proofs of adequacy 2 use confluence (commutation of $→$ with itself) and semi-standardization.
But confluence is harder to prove.

We perhaps could have shown ${← · ↦} ⊆ {↦^= · ←^*}$ directly, without mentioning $\Int$.
Our approach lets us reuse the already established substitution lemmas for $\Int$.

\section{Contextual equivalence}

\begin{theorem}[Contextual equivalence, observing termination to a value]
	\label{ctxeqv1}
	If $e → e'$, then for all general contexts $C$, $C[e]$ evals to a value iff $C[e']$ evals to a value.%
\end{theorem}
\begin{proof}
	By congruence of reduction and adequacy.
\end{proof}

Another notion of contextual equivalence observes termination in general.
We can repeat a similar argument by characterizing the non-value terms
where evaluation can't proceed.

\begin{lemma}[Stuck terms]
	Stuck terms have this form:
	$$s ::= K[x\:v] │ E[\S κ.\,e] │ K[κ⟦v⟧]$$
\end{lemma}
\begin{lemma} Assume $e \Int e'$. Then $e$ is stuck iff $e'$ is stuck.
\end{lemma}

\begin{theorem}[Contextual equivalence, observing termination]
	If $e → e'$, then for all contexts $C$, $C[e]$ terminates iff $C[e']$ terminates.
\end{theorem}

These two notions of contextual equivalence do differ:
$\S κ.\,Ω$ and $Ω$ are contextually equivalent by the first definition,
but not the second \cite{bisim}.



\chapter{Confluence}
Confluence is the property
that diverging reduction sequences can meet.
In practical terms, it lets us perform reductions in any order
and always reach the same result.

We haven't managed to prove confluence for
the entire calculus.
We present a proof using the parallel reduction technique for the subcalculus without
data in delimiters and without \KwLet{} reassociation.
These two features might look like the most benign of the bunch,
but they pose great technical difficulties.

\section{Parallel reduction}
Parallel reduction (figure \ref{parallel}) allows us to perform reductions (figure \ref{reduction})
in many places of the term at once.
The tail-of-delimiter reductions are implemented by parameterizing
by two modes (ranged over by metavariable $M$):
\textit{g}eneral and tail of \textit{d}elimiter.
Moreover, we need to perform consecutive reduction steps in some situations:
\begin{enumerate}
\item
	Consider a peak involving $\KwLet{}.\S$ and some tail-of-reset reduction:
	$$\S κ.\,e\subst{κ}{\Let{x}{□}{t}} \Rap{d} \Let{x}{\S κ.\,e}{t} \Par{d} \Let{x}{\S κ.\,e}{t'}$$
	To perform tail-of-reset reductions in the $t$ substituted on the left,
	we need to perform the substitution $κ{:=}⟨□⟩$ first and then reduce.
	So we are forced to perform a $dL.\S$ step on the left,
	and so $\KwLet{}.\S$ followed by $dL.\S$ on the right.

	Substituting the delimiter first and then reducing works only because
	$κ⟦e⟧$ and $⟨e⟩$ are terms of the same size
	and we can induct on size in the proof of diamond property.
	This no longer holds if we add data to delimiters.
\item
	The redex $κ⟦\S κ'.\,e⟧$ has to be generalized to $κ⟦E[\S κ'.\,e]⟧$ for the substitution lemma to hold
	(consider $κ:=κ⟦\Let{x}{□}{t}⟧)$.
	Likewise for $⟨·⟩$ instead of $κ⟦·⟧$.

\item
	The addition of $\A.d$ forces us to combine the generalizations described in the previous two points,
	resulting in the very last rule in the figure.
	% TODO motivating peak

\end{enumerate}

\begin{figure}
	\begin{mathpar}

	\inferrule{}
	{x \Par{M} x}

	\inferrule{e \Par{g} e'}
	{λx.\,e \Par{M} λx.\,e'}

	\inferrule{}
	{□ \Par{M} □}

	\inferrule{v \Par{g} v' \\ u \Par{g} u'}
	{v\:u \Par{M} v'\:u'}

	\inferrule{e \Par{g} e' \\ t \Par{M} t'}
	{\Let{x}{e}{t} \Par{M} \Let{x}{e'}{t'}}

	\inferrule{e \Par{g} e'}
	{\S κ.\,e \Par{M} \S κ.\,e'}

	\inferrule{e \Par{d} e'}
	{⟨e⟩ \Par{M} ⟨e'⟩}

	\inferrule{e \Par{g} e'}
	{κ⟦e⟧ \Par{M} κ⟦e'⟧}

	\inferrule{e \Par{g} e' \\ v \Par{g} v'}
	{(λx.\,e)\:v \Par{M} e'\subst{x}{v'}}

	\inferrule{t \Par{g} t' \\ v \Par{g} v'}
	{\Let{x}{v}{t} \Par{M} t'\subst{x}{v'}}

	\inferrule{v \Par{g} v'}
	{⟨v⟩ \Par{M} v'}

	\inferrule{e \Par{g} e' \\ t \Par{M} t'}
	{\Let{x}{\S κ.\,e}{t} \Par{M} \S κ.\,e'\subst{κ}{κ⟦\Let{x}{□}{t'}⟧}}

	\inferrule{e\subst{κ}{⟨□⟩} \Par{g} e'}
	{⟨\S κ.\,e⟩ \Par{M} e'}

	\inferrule{e \Par{g} e' \\ E \Par{d} E'}
	{⟨E[\S κ'.\,e]⟩ \Par{M} e'\subst{κ'}{⟨E'⟩}}

	\inferrule{e \Par{g} e' \\ E \Par{g} E'}
	{κ⟦E[\S κ'.\,e]⟧ \Par{M} e'\subst{κ'}{κ⟦E'⟧}}
	\\

	\inferrule{e\subst{κ}{⟨□⟩} \Par{g} e'}
	{\S κ.\,e \Par{d} \A\,e'}

	\inferrule{e \Par{d} e'}
	{\A⟨e⟩ \Par{d} e'}

	\inferrule{v \Par{g} v' }
	{\A\,v \Par{d} v'}

	\inferrule{e \Par{g} e' \\ E \Par{g} E'}
	{\Let{x}{E[\S κ.\,e]}{t} \Par{d} \A e'\subst{κ}{⟨E'⟩}}

	\end{mathpar}
	\caption{Parallel reduction.}
	\label{parallel}
\end{figure}

\begin{lemma}
	${→} ⊆ {\Par{g}} ⊆ {→^*}$
\end{lemma}

\begin{lemma}
	${\Par{g}} ⊆ {\Par{d}}$
\end{lemma}

\begin{lemma}[Substitution]
	\item
	\begin{enumerate}
		\item If $e \Par{M} e'$ and $v \Par{g} v'$, then $e\subst{x}{v} \Par{M} e'\subst{x}{v'}$;
		\item If $e \Par{M} e'$ and $D \Par{g} D'$, then $e\subst{κ}{D} \Par{M} e'\subst{κ}{D'}$.
	\end{enumerate}
\end{lemma}

\begin{theorem}[Diamond property]
	${\Rap{M} · \Par{M}} ⊆ {\Par{M} · \Rap{M}}$
\end{theorem}

\begin{corollary}[Confluence]
	${←^* · →^*} ⊆ {→^* · ←^*}$
\end{corollary}


\section{The challenges of \textsf{let} reassociation}
\label{problet}

The $\KwLet$ reassociation reduction (a.k.a.\  $\KwLet{}$ floating, $\KwLet{}$ associativity)
$$\RLet{x}{\Let{y}{e}{t_1}}{t_2} → \Let{y}{e}{\Let{x}{t_1}{t_2}}$$
flattens the structure of the term by getting rid of $\KwLet$s nested on the left
(here raised).
It has this critical pair with itself:
$$
\begin{tikzpicture}
	\node (E1) at (2,5) {$\RLet{x}{\RLet{y}{\Let{z}{e}{t_1}}{t_2}}{t_3}$};
	\node (E2) at (6,3) {$\RLet{y}{\Let{z}{e}{t_1}}{\Let{x}{t_2}{t_3}}$};
	\node (E3) at (0,2) {$\RLet{x}{\Let{z}{e}{\Let{y}{t_1}{t_2}}}{t_3}$};
	\node (E3') at (2,1) {$\Let{z}{e}{\RLet{x}{\Let{y}{t_1}{t_2}}}{t_3}$};
	\node (E4) at (4,0) {$\Let{z}{e}{\Let{y}{t_1}{\Let{x}{t_2}{t_3}}}$};
	\path[->]
		(E1) edge (E2)
		(E1) edge (E3);
	\path[->,dashed]
		(E2) edge[bend left] (E4)
		(E3) edge (E3')
		(E3') edge (E4);
	%\draw [brown] (current bounding box.south west) rectangle (current bounding box.north east);
\end{tikzpicture}
$$
Two steps are needed on the left to complete the diagram.
This calls for the following generalization, which can do it in one step and \textit{does} have the diamond property:
$$\Let{x}{L[t_1]}{t_2} → L[\Let{x}{t_1}{t_2}]$$
However, this is not enough for \textit{parallel} reduction.
Here, the redex above overlaps with two different redexes below:
$$
\begin{tikzpicture}
	\node (E1) at (0,0) {$\RLet{x}{\RLet{y}{\RLet{z}{\Let{w}{e}{t_1}}{t_2}}{t_3}}{t_4}$};
	\node (E2) at (5.3,1.1) {$\RLet{x}{\RLet{z}{\Let{w}{e}{t_1}}{\Let{y}{t_2}}{t_3}}{t_4}$};
	\node (E3) at (5.3,-1.1) {$\RLet{y}{\Let{w}{e}{\Let{z}{t_1}}{t_2}}{\Let{x}{t_3}}{t_4}$};
	\path[->] (E1.east) edge[] (E2.south);
	\path[->>] (E1.east) edge[] (E3.north);
	%\draw [brown] (current bounding box.south west) rectangle (current bounding box.north east);
\end{tikzpicture}
$$
To complete this diagram in one parallel reduction step,
we would need to have not only length-wise,
but also a depth-wise generalization
of $\KwLet$ reassociation.
We don't provide a definition here, since we haven't managed to prove any attempt right.

The other challenge is that a $\KwLet{}.\S$ reduction can tear apart a $\KwLet{}.\KwLet{}$ redex:
$$
\begin{tikzpicture}
	\node (E1) at (0,0) {$\Let{x}{\Let{y}{\S κ.\,e}{t_1}}{t_2}$};
	\node (E2) at (3.5,-2) {$\Let{y}{\S κ.\,e}{\Let{x}{t_1}{t_2}}$};
	\node (E3) at (-3.5,-1.333) {$\Let{x}{\S κ.\,e\subst{κ}{κ⟦\Let{y}{□}{t_1}⟧}}{t_2}$};
	\node (E3') at (-3.5,-2.666) {$\S κ.\,e\subst{κ}{κ⟦\Let{x}{\Let{y}{□}{t_1}}{t_2}⟧}$};
	\node (E4) at (0,-4) {$\S κ.\,e\subst{κ}{κ⟦\Let{y}{□}{\Let{x}{t_1}{t_2}}⟧}$};
	\path[->] (E1) edge node[above right, pos=0.6, text=gray] {$\KwLet{}.\KwLet{}$} (E2);
	\path[->] (E1) edge node[above left, pos=0.8, text=gray] {$\KwLet{}.\S$} (E3);
	\path[->,dashed] (E3) edge node[left, text=gray] {$\KwLet{}.\S$} (E3') (E2) edge node[below right, pos=0.3, text=gray] {$\KwLet{}.\S$} (E4);
	\path[->>,dashed] (E3') edge node[left, xshift=-10pt, text=gray] {$\KwLet{}.\KwLet{}$} (E4);
\end{tikzpicture}
$$
We need a successive $\KwLet{}.\S$ step to make the $\KwLet{}.\KwLet{}$ redexes whole, now after structural substitution.

\section{Towards a proof for the full calculus}
The difficulties lead us to search for another approach to proving confluence.

There is a way of defining
parallel reduction indirectly, by first establishing a theory of residuals.
This involves contracting previously marked sets of redexes in a term.
Because of the situations where redexes are torn apart, this might be impossible.

A more promising approach relies on proving termination of reductions.
De Groote's proof of strong normalization of $\KwLet{}.\S$ \cite{Groote}
should be rather easily adaptable to include $k.\S$ and $d.\S$.
The tail-of-reset reductions would involve more work.
The biggest challenge seems to be including $\KwLet{}.\KwLet{}$, though.
Then, the standard argument by Newman's lemma and Hindley-Rosen's lemma should work.

The method of decreasing diagrams \cite{dd} reduces the problem to a well-ordered
labeling of reductions and a form of local confluence, viz.
\begin{center}
\begin{tikzpicture}[node distance=2cm, auto, scale=1, every node/.style={scale=1}]
\useasboundingbox (-0.5, -0.5) rectangle (5.5, 3.5);

\node (a) at (0, 3) {};
\node (b) at (5, 3) {};
\node (c) at (0, 0) {};
\node (d) at (5, 0) {};

\node (c1) at (2, 0) {}; % First split for c->d
\node (c2) at (3, 0) {}; % Second split for c->d
\node (b1) at (5, 2) {}; % First split for b->d
\node (b2) at (5, 1) {}; % Second split for b->d

\draw[->] (a) -- node[above] {$β$} (b); % a to b
\draw[->] (a) -- node[left] {$α$} (c); % a to c

\draw[->, dashed] (c) -- node[below] {${<}α$} (c1); % c to c1
\draw[->, dashed] (c1) -- node[below] {$β$} (c2); % c1 to c2
\draw[->, dashed] (c2) -- node[below] {${{<}α} ∪ {{<}β}$} (d); % c2 to d

\draw[->, dashed] (b) -- node[right] {${<}β$} (b1); % b to b1
\draw[->, dashed] (b1) -- node[right] {$α$} (b2); % b1 to b2
\draw[->, dashed] (b2) -- node[right] {${{<}α} ∪ {{<}β}$} (d); % b2 to d

\node at (c1) [above=0.2cm, left=0.1cm] {$*$};
\node at (c2) [above=0.2cm, left=0.1cm] {$=$};
\node at (d) [above=0.4cm, left] {$*$};

\node at (b1) [above=0.2cm, left] {$*$};
\node at (b2) [above=0.2cm, left] {$=$};
\node at (d) [above=0.2cm, left=0.2cm] {$*$};
\end{tikzpicture}
\end{center}
It is not easily applied in our case.
Consider the $\KwLet{}.\S$-$\KwLet{}.\KwLet{}$ critical pair illustrated previously.
We can try labeling reductions with their names at first.
\begin{enumerate}
	\item
If $\KwLet{}.\S < \KwLet{}.\KwLet{}$, then
the diagram is not decreasing because $\KwLet{}.\KwLet{}$ is used many times on the left.
Either $\KwLet{}.\KwLet{}$ has to be parallelized, or the order on $\KwLet{}.\KwLet{}$ has to be refined.
	\item
	If $\KwLet{}.\S > \KwLet{}.\KwLet{}$, then
the diagram is not decreasing because of the follow-up $\KwLet{}.\S$ reduction on the left.
We could refine the order on $\KwLet{}.\S$ labels by introducing
self-labeling ordered by structural reductions
($\KwLet{}.\S^e > \KwLet{}.\S^{e'}$ iff $e \xrightarrow{Str}^+ e'$),
but then we would have to prove them strongly normalizing.
\end{enumerate}
An idea to try is ordering by the depth at which reduction occurs.


\chapter{Abella mechanization}

We have formalized the adequacy and partial confluence theorems in the Abella proof assistant\footnote{
	With the yet unreleased bugfix by the author \cite{abellafix}.
}.
Abella follows the tradition of Church's Simple Theory of Types
in representing object-level variable binders as meta-language lambda-abstractions.
This approach to variable binding (known as \textit{HOAS} or \textit{lambda-tree} syntax)
allows reasoning closer to informal pen-and-paper arguments, as it eliminates
much of the noise related to variables and substitution present in other approaches.

\section{Higher-order abstract syntax}

As an example, we represent expressions in the lambda-calculus in Abella by defining constants \lstinline{lam}, \lstinline{app} of the following types:
\begin{lstlisting}
Kind expr   type.
Type lam    (expr -> expr) -> expr.
Type app    expr -> expr -> expr.
\end{lstlisting}
The object-level expression $λx.\,x\,x$ is represented as \lstinline{lam (x\ app x x)},
where \lstinline{x\ ...} is Abella's notation for lambda-abstractions.
We can drop the parentheses and write \lstinline{lam x\ app x x}.
Since the meta-language is typed, strong normalization holds and we can't have troublemakers such
as self-application on the meta level.

With the definition of reduction below, we obtain a \textit{higher-order rewriting system}:
\begin{lstlisting}
Define red : expr -> expr -> prop by
  red (app (lam M) N) (M N);
  red (app M N) (app M' N) := red M M';
  red (app M N) (app M N') := red N N';
  red (lam E) (lam E') := nabla x, red (E x) (E' x).
\end{lstlisting}
The first rule is the $β$-reduction, wherein substitution is realized as application in the meta-language.
Congruence rules defined by Prolog-like clauses follow,
the last of which introduces the \textit{nabla} ($\nabla$) quantifier.

The meta-expression $\nabla x.\,…$ in Abella's logic introduces a fresh nominal constant $x$.
In practice, nabla lets us operate on object-level terms with free variables:
in the congruence rule for object-level $λ$-abstractions,
we descend under the binder by substituting a fresh nominal constant for the bound variable.
Unlike most formalizations of the $λ$-calculus, we don't have a constant like \lstinline{lam} or \lstinline{app} for variables.
This embodies Perlis' epigram ``There is no such thing as a free variable'':
namely, a variable is always bound
either by the object-level \lstinline{lam x\}
or by the meta-level \lstinline{nabla x}.

Structural substitution poses no problem.
As shown by Abel, continuations can be seen as terms of type \lstinline{expr -> expr} \cite{3rd}.
Plugging an expression \lstinline{e} into a continuation \lstinline{k} (which we have denoted $κ⟦e⟧$) is again just
meta-level application: \lstinline{k e}.
Rules such as $\KwLet{}.\S$ transcribe rather directly:
$$\Let{x}{\S κ.\,e}{t} → \S κ.\,e\subst{κ}{κ⟦\Let{x}{□}{t}⟧}$$
\begin{center}
\lstinline{red (let (s k\ E k) T) (s k\ E (o\ k (let o T)))}
\end{center}
The main differences being we don't need to name the variable bound in $t$,
but do need to explicitly bind the hole ($□$) as a variable \lstinline{o} in
the substituted extended continuation.
Because of $η$-equivalence in the meta-language,
we can even write \lstinline{s E} instead of \lstinline{s k\ E k} on the left.
The $β$-equivalence below shows that the structural substitution does the right thing:
\begin{center}
	\lstinline{(o\ k (let o T)) E = k (let E T)}
\end{center}
%This suggests the view of the $κ⟦e⟧$ syntax as the point where the plug meta-operation $K[e]$ gets stuck.

\section{The power of nabla}

HOAS doesn't need the $\nabla$ quantifier.
Indeed, it's not available in Abella's \textit{specification logic} $λ$-Prolog.
Abella takes a two-level approach, where the weaker specification logic
embeds into the stronger \textit{reasoning logic}.
The lack of $\nabla$ in the specification logic is a source of free theorems (e.g.\, about substitution)
that can be used in the reasoning logic.

Even though the lack of $\nabla$ precludes us from matching on free variables,
there is a general workaround that lets us work with terms with binders:
when we descend under a binder,
we use a \textit{universal} quantifier \lstinline{pi} to represent the bound variable
and add all consequences of it being a variable we will need to the local context of assumptions.
For example, in the definition of parallel reduction for the lambda calculus,
we add the local assumption $x \Rrightarrow x$ in the clause for $λx.\,M \Rrightarrow λx.\,M'$:
\begin{lstlisting}
par (lam M) (lam M') :- pi x\ par x x => par (M x) (M' x).
\end{lstlisting}
In Abella's reasoning logic, we can express the rule $x \Rrightarrow x$ directly:
\begin{lstlisting}
nabla x, par x x;
par (lam M) (lam M') := nabla x, par (M x) (M' x);
\end{lstlisting}

Abel's work on the $λμ$-calculus is in Twelf, and the situation there
is similar to Abella's specification logic%
%: no $\nabla$ quantifier.
.
Abel encountered issues with defining parallel reduction for the $λμ$-calculus in Twelf \cite{3rd}.
There are no issues when we take the $\nabla$ quantifier approach in Abella.
Not only is parallel reduction definable,
but, as noted by Accattoli \cite{pearl},
formalizations using only the reasoning logic
can be significantly simpler than those using the mentioned trick,
and so this is the approach we take.
With that, we believe our work constitutes the first mechanized proof of confluence for a variant of the $λμ$-calculus.

\section{The formalization}
We have introduced the concept of HOAS using $λ$- and $λμ$-calculi as running examples.
Our calculus differs from them in naming and in the separate syntactic category of values.
Moreover, the Abella formalization differs from the definitions in Chapter \ref{Syntax}:
\begin{enumerate}
	\item
		We have an expression $\Ask(D)$ instead of a value $\Ask(κ)$,
		and instead of extending structural substitution we have the following evaluation (and reduction) rule:
		$$\Ask(⟨E╱v⟩) ↦ v$$
		We believe that working with the grammar $\Ask(κ)$ on paper is more convenient,
		but in Abella we wanted to avoid formalizing the normalization to that form.%
		\footnote{
			Having $e ::= \Ask(D) │ ...$ with the explicit evaluation step feels spiritually close
			to having $e ::= D⟦e⟧ │ ...$ with explicit evaluation steps for plugging evaluation frames
			(which get stuck on $D ≡ κ⟦□⟧$).
			On paper we want to avoid both, but only the latter can be subsumed by $λ$-equivalence in Abella.
		}
	\item
		We don't use at-a-distance rules involving contexts, such as:
%		$$κ⟦E[\S κ'.\,e]⟧ ↦ e\subst{κ'}{κ⟦E⟧}$$
		$$D[\S κ'.\,e] ↦ e\subst{κ'}{D}$$
		A direct transcription of this pattern would create hard unification problems
		involving a unification variable applied to non-variables.
		Furthermore, we would have to introduce a proposition that checks
%		that a context \lstinline{expr -> expr} is an evaluation context.
		that a context \lstinline{expr -> expr} is a $D$ context.
		We instead introduce auxiliary relations that walk the relevant contexts, for example:
		\begin{lstlisting}
nabla k, step (k (E k)) (E' k k) :=
  nabla k, stepc (E k) (E' k);
stepc (shift0 E) E;
stepc (let E T) (k\ E' (o\ k (let o T))) :=
  stepc E E';
		\end{lstlisting}
		That is, \lstinline{stepc} extracts the body of an $\S$ in evaluation position and substitutes the context, semi-formally:
		$$\texttt{stepc}\:E[\S κ.\,e] \:(κ.\,e\subst{κ}{κ⟦E⟧})$$
\end{enumerate}

\chapter{Related work}
%We mark foreign syntax in \foreign{blue} and potential modifications to our calculus in green.

\section{Distributing delimiters}
There is a strand of work which tackles static delimited control from the opposite direction.
Whereas we use structural reduction so that $\S$ moves closer to the delimiter, that strand's defining feature is
the delimiter distributing over \KwLet{} expressions so that \textit{a} delimiter can meet the control operator:
\cite{saleh, karachalias, ppdp21, agen}
\begin{align*}
	\foreign{⟨\Let{x}{e}{t} ¦ y.\,t_r⟩ → ⟨e ¦ x.\, ⟨t ¦ y.\,t_r⟩⟩}
\end{align*}
There, the return clause is an integral part of the syntax.

We note that the equational theory (equivalence closure of reduction) of our calculus
contains the relevant reductions (after macro-translation to our calculus).\footnote{
	In \cite{agen,ppdp21} values (meant to be $λ$-abstractions) are used where we have binder syntax,
	so some applications of the $η$-rule might also be needed.
}
\begin{align*}
⟨\Let{x}{e}{t} ¦ y.\,t_r⟩
&≡ ⟨\Let{y}{\Let{x}{e}{t}}{\A\,t_r}⟩ \\
&→ ⟨\Let{x}{e}{\Let{y}{t}{\A\,t_r}}⟩ \tagmath{\KwLet{}.\KwLet{}} \\
&← ⟨\Let{x}{e}{\A\,⟨\Let{y}{t}{\A\,t_r}⟩}⟩ \tagmath{\A.d} \\
&≡ ⟨e ¦ x.\, ⟨t ¦ y.\,t_r⟩⟩
\end{align*}
While both this and our approach can statically handle any effect separated
from the delimiter by $\KwLet$ expressions,
the reverse reduction $←$
reveals that in our view this is not purely a simplification.
Indeed, turning $\KwLet$s into delimiters is rather wasteful,
since the latter typically have a much higher run-time cost.

The base case of the operator directly within the delimiter:
\begin{align*}
⟨\shiftz\,k.\,e ¦ y.\,t_r⟩
&≡ ⟨\Let{y}{\S κ.\,\Let{k}{λx.\,κ⟦x⟧}{e}}{\A\,t_r}⟩ \\
&→ ⟨\S κ.\,\Let{k}{λx.\,κ⟦\Let{y}{x}{\A\,t_r}⟧}{e}⟩ \tagmath{\KwLet{}.\S} \\
&→ \Let{k}{λx.\,⟨\Let{y}{x}{\A\,t_r}⟩}{e} \tagmath{d.\S} \\
&→ \Let{k}{λy.\,⟨\A\,t_r⟩}{e} \tagmath{\KwLet{}.v} \\
&→ \Let{k}{λy.\,t_r}{e} \tagmath{d.\S} \\
&→ e\subst{k}{λy.\,t_r}
\end{align*}

Similar calculations apply for the rules for effect handlers \cite{saleh, karachalias, agen}.
\begin{align*}
&\Handle \Let{x}{e}{t} \With y\,k.\,t_h¦ z.\,t_r \\
&≡ ⟨\Let{z}{\Let{x}{e}{t}}{\A\,t_r} ╱ λy\,k.\,t_h⟩ \\
&→ ⟨\Let{x}{e}{\Let{z}{t}{\A\,t_r}} ╱ λy\,k.\,t_h⟩  \tagit{\KwLet{}.\KwLet{}} \\
&← ⟨ \Let{x}{e}{\A\,⟨\Let{z}{t}{\A\,t_r}}╱ λy\,k.\,t_h⟩ ╱ λy\,k.\,t_h⟩  \tagit{$\A$.d} \\
&≡ \Handle e \With y\,k.\,t_h ¦ x.\,\Handle t \With y\,k.\,t_h ¦ z.\,t_r
\end{align*}
The calculus in \cite{agen} also includes the \KwLift{} construct.
This expression former makes operations inside skip the nearest effect handler.
In the single-effect (single-label) setting, it can be easily macro-expressed \cite[Section 3.2]{fscd19}:
$\Lift e ≡ \S κ.\,\Let{x}{e}{κ⟦x⟧}$.
This is enough to simulate the rule for lift-handler interaction \cite[\textbf{DH}.\textit{lift}]{agen}:
\begin{align*}
	\Handle \Lift e \With x\,k.\,t_h ¦ y.\,t_r
	&≡ ⟨\Let{y}{\S κ.\,\Let{x}{e}{κ⟦x⟧}}{\A\,t_r}╱λx\,k.\,t_h⟩ \\
	&→^2 \Let{x}{e}{⟨\Let{y}{x}{\A\,t_r}╱λx\,k.\,t_h⟩} \\
	&→ \Let{y}{e}{⟨\A\,t_r╱λx\,k.\,t_h⟩} \\
	&→ \Let{y}{e}{t_r}
\end{align*}

Our equational theory is in fact strictly more powerful:
the delimiter-oriented reductions cannot do anything when there
is no delimiter, but we can (subsection \ref{strred}).

\section{shift0 axiomatization}
It might be interesting to compare the axiomatization of $\shiftz$ by Materzok \cite{materzok}.
We pick the most interesting rules and restate them into more familiar notations.

\subsection*{shift0/reset}

\begin{equation*}
	\foreign{\shiftz\,k.\,⟨\Let{x}{e}{\abort\,k\,x}⟩ = e} \tag{\foreign{$η_{⟨·⟩}$}}
\end{equation*}
This $η$-rule changes behavior if there is no outer delimiter,
but inside $⟨L⟩$ we could use $\A.d$ twice and add \KwLet{} identity ($\Let{x}{e}{x} → e$) to get the same result.

\begin{equation*}
	\foreign{⟨\Let{x}{e_2}{\abort ⟨e_1⟩}⟩ = ⟨\Let{x}{e_2}{e_1}⟩} \tag{\foreign{$⟨λ⟩$}}
\end{equation*}
Clearly an instance of $\A.d$.

\begin{equation*}
	\foreign{\Let{x}{e}{E[x]} = E[e]} \tag{\foreign{$β_Ω$}}
\end{equation*}
Expressible with $\KwLet{}.\KwLet{}$ and $let.id$: $\Let{x}{e}{E[x]} ←^* E[\Let{x}{e}{x}] → E[e]$.

\subsection*{shift0/dollar}
\begin{equation*}
	\foreign{\shiftz\,k.\,⟨e ¦ y.\,k\,y⟩ = e} \tag{\foreign{$η_\$$}}
\end{equation*}
Again, expressible with $\A.d$ in $⟨L⟩$ contexts.

\begin{equation*}
	\foreign{⟨E[e] ¦ y.\,t⟩ = ⟨e ¦ x.\,⟨E[x]¦y.\,t⟩⟩} \tag{\foreign{$\$_E$}}
\end{equation*}
This is $(β_Ω)$ and the delimiter-distributing reduction from the previous section.

\section{Delimited \texorpdfstring{$λμ$}{lambda-mu}}

Ariola and Downen's comprehensive study \cite{delimcomp} views delimiters
as ``rebindable top-levels''.
The operational semantics contains reductions which appear to peek under binders
(\foreign{$μ \hat{\mathsf{tp}}.\,⟦\hat{\mathsf{tp}}⟧v ↦ v$})
and encodings of operators such as $\shiftz$ are much more complicated.
We wonder if these are consequences of using Parigot's original syntax instead of de Groote's more
liberal variant \cite{Groote94} that doesn't
separate out commands (named terms) $\foreign{⟦α⟧t}$ and doesn't force the body of $μ$-abstraction
to be a command.

\section{Fine-grained syntax for algebraic operations}
The original syntax for algebraic operations involved continuations.
What we may now express as the generic effect $arb : \mathsf{unit} → \mathsf{bool}$
can be equivalently expressed as an algebraic operation $or : (\mathsf{unit} → τ)^2 → τ$
with the equivalences $arb\,() = or(λ\_.\,\true, λ\_.\,\false)$ and
$or(k_1,k_2) = \mathsf{if}\;arb\,()\;\mathsf{then}\; k_1 () \;\mathsf{else}\;k_2 ()$ \cite{alggen}
\footnote{$2 ≅ \mathsf{bool}$}.

The equality for handling \cite{handlers} shouldn't be surprising:
$$\Handle \Op(\overline{v_i}) \With \Op(\overline{k_i}).\,t = t\overline{\subst{k_i}{λx.\,\Handle v_i\:x \With \Op(\overline{k_i}).\,t}}$$
The connection of algebraic operations and control wasn't explicitly noted at first,
but can be seen in the naturality condition for algebraic operations,
which states that evaluation contexts commute with operations \cite{logic, handling}:
$$E[\Op(\overline{λx_i.\,t_i})] = \Op(\overline{λx_i.\,E[t_i]})$$

The calculus in \cite{hia} has an intermediate approach,
where an operation has only one continuation parameter.
The intended surface syntax is of the generic effect form $\Op v$,
which is elaborated to start with an identity continuation $\Op v\,(λx.\,x)$.
The step relation captures the evaluation context in a fine-grained manner:
$$\Let{y}{\Op v\,(λx.\,t_1)}{t_2} ↦ \Op v\,(λx.\,\Let{y}{t_1}{t_2})$$
This bears similarity to our approach based on structural reduction.
However, we don't see a way to express our optimizations without introducing $\abort$ in some form.


\section{Expressing handlers using shift0}
Previous encodings of handlers using $\shiftz$ worked by representing the handler
clause as an evaluation frame \textit{below} the delimiter \cite{effmondel, fscd19}.

In the most popular version,
an operation captures the continuation and returns a $λ$-abstraction
which is waiting to be applied to the handler clause.
$$\Op v ≡ \shiftz\,k.\,λh.\,h\:v\:(λy.\,k\:y\:h) \quad\quad \Handle e \With x\,k.\,t ≡ ⟨e¦x.\,λh.\,x⟩\,(λx\,k.\,t)$$
Here, we cannot use general optimizations for $\shiftz$ to statically handle effects,
because it is not guaranteed that the application will be waiting under the delimiter.
The invariant could be broken by $\shiftz$s that are not of the $\Op v$ form.

This encoding is very similar to the encoding of dynamic binding as delimited control \cite{delimdyn}
by Kiselyov et al.
It's not hard to come up with encodings that directly express the handler clause $h$ as a dynamically bound parameter,
either with the binder below the delimiter (on the machine stack):
$$\Op v ≡ \shiftz\,k.\,h\:v\:k \quad\quad \Handle e \With x\,k.\,t ≡ \Dlet{h}{λx\,k.\,t}{⟨e⟩}$$
or above:
$$\Op v ≡ \Let{h'}{h}{\shiftz\,k.\,h'\:v\:k} \quad\quad \Handle e \With x\,k.\,t ≡ ⟨\Dlet{h}{λx\,k.\,t}{e}⟩$$
The latter option seems preferable, since the d$\KwLet$ cannot be separated from the delimiter by a $\shiftz$
and therefore general optimizations should apply.

We have chosen to merge the two constructs which enhance execution contexts into one:
reset binds the dynamic parameter and we can refer to it through the continuation variable.
The problem with conventional syntax dynamic parameters $p$ and their binders $\Dlet{p}{e}{t}$ is
the same as with for operations and handlers:
they don't allow a fine-grained reduction,
except for dynamic binders distributing over lexical binders.


\section{Expressing return clauses}
Recall our encoding of return clauses (figure \ref{shorthands}):
$$⟨e¦x.\,e_r⟩ ≡ ⟨\Let{x}{e}{\A\,e_r}⟩$$
$$\Handle e \With x,k.\,e_h ¦ x.\,e_r ≡ ⟨\Let{x}{e}{\A\,e_r}¦λx,k.\,e_h⟩$$
A similar equivalence has been proven for typed algebraic effects \cite{hwc}:
$$\foreign{\Handle e \With x,k.\,e_h ¦ x.\,e_r ≈\Handle \Let{x}{e}{\Lift{e_r}} \With x,k.\,e_h}$$
Our encoding is clearly the natural one, since its correctness
is proven just by calculation of a few evaluation steps.

The idea is that we want to prevent effects in $e_r$ from reaching the handler.
After $e$ has finished evaluating and we start evaluating the rhs of $\KwLet$,
we know that the frame at the top of the stack will be the handler.
Our solution is popping the handler with $\abort$,
theirs is pushing a $\KwLift$ stack frame that makes effects skip the $\KwLift$-handler pair \cite[Appendix A]{hwc}.

\section{Tail reductions and letcc}
The central idea in our paper is embodied by the $dL.\S$ reduction:
$$⟨L[\S κ.\,e]⟩ → ⟨L[\A\,e\subst{κ}{⟨□⟩}]⟩$$
It is tempting to decompose $\S$ into its constituent parts:
a $\keyword{letcc}$ which binds the current continuation without aborting, and an abort $\A$:
$$\S κ.\,e ≡ \keyword{letcc}\,κ.\,\A\,e$$
Then we could simulate $dL.\S$ using a reduction that pushes $\keyword{letcc}$ out of the tail:
$$\Let{x}{e}{\keyword{letcc}\,κ.\,t} → \keyword{letcc}\,κ.\,\Let{x}{e}{t}$$
Analogous reductions have been considered for undelimited continuations \cite{sabry}.

There are issues with this approach, though:
\begin{enumerate}
	\item
		The above reduction isn't semantics-preserving. If $e$ above is the nonterminating $Ω$,
		then the left side diverges, while the right side gets stuck on searching for a delimiter.
		We could ensure a delimiter is found by performing the reduction only in $⟨L⟩$,
		but then it is unclear if there are significant benefits to this approach.

	\item
		Because $\keyword{letcc}$ binds the continuation and keeps running in it,
		$$⟨E[\keyword{letcc}\,κ.\,e]⟩ ↦ ⟨E[e\subst{κ}{⟨E⟩}]⟩$$
		it seems inherently incompatible with one-shot (linear) continuations.
		This is a design choice or a limitation of some implementations of control, e.g.\,OCaml 5.
\end{enumerate}



\section{Confluence}

Proofs of confluence have always been notoriously difficult
and many early attempts for the $λ$-calculus were flawed.

The proof alongside the introduction of the $λμ$-calculus \cite{parigot92} also turned out to be incorrect \cite{baba}.
The fix involves performing multiple structural reduction steps \cite{baba,koji}, which we have employed in our formalization
and verified that it works also with our tail-of-delimiter reductions.

Herbelin and Zimmerman \cite{Herbelin} claim that a proof by parallel reduction is possible for a $λμ$-calculus with
$\KwLet$ reassociation, but provide no details.
As shown in section \ref{problet}, parallelizing this reduction is not trivial.
We also don't see how they could deal with the $\KwLet{}.\S$-$\KwLet{}.\KwLet{}$ critical pair
unless they add a $κ⟦\Let{x}{e}{t}⟧ → \Let{x}{e}{κ⟦t⟧}$ reduction, which is similar to theirs
$x(\Let{x}{e}{t}) → \Let{x}{e}{xt}$ and seems to be valid in the undelimited setting.

The proof for the $\shiftz$ calculus with delimiter distribution in \cite{ppdp21} relies on a dubious reduction to local confluence,
and so we believe it is also incorrect.
%which is not a valid argument (take $\Rightarrow=→$ for a counterexample, it is known that local confluence does not imply confluence). Diamond property is needed instead of local confluence.


\chapter{Future work}

\section{Purity-aware reductions}
We should be able to perform much stronger optimizations
if we know that an expression doesn't perform control effects.
We believe a particularly elegant way to accomplish that in the untyped setting is to add
\textit{purity assertions} to $\KwLet{}$ expressions,
let's write ${\Letp{x}{e}{t}}$.
The purity assertion ensures that $e$ does not attempt to capture the continuation by crashing the program when it does.
Formally, the $\KwLet{}.\S$ reduction is allowed only for impure $\KwLet{}$s (without the assertion)
and $E$ contexts are composed of impure $\KwLet{}$s.
Then, we could add reductions such as $κ⟦\Letp{x}{e}{t}⟧ → \Letp{x}{e}{κ⟦t⟧}$.
Many examples from section \ref{secreduction} could be strengthened or generalized:
we could optimize consecutive effects separated by pure expressions,
get rid of unnecessary delimiters in the nondeterminism example,
optimize tail-resumptive $\S$ bodies if the tail context is pure.

We could generate purity assertions during lowering from syntax with type-and-effect annotations
to an untyped intermediate language,
it looks like this approach would subsume many of the previous purity-aware optimizations \cite{karachalias, saleh}.

\section{Multi-prompt (labeled) control}

We believe all results transfer to multi-prompt delimited control, where we have independent sets of labeled operators $S^\ell κ.\, e$, $⟨e⟩^\ell$.
For working with handlers of multiple effects, having the delimiter tagged with a \textit{set} of labels might be necessary,
the carried value should also be generalized to a map from labels to values.
Naturally, purity assertions also could be refined to block or allow specific listed effects.

Such an extension would probably need at least a mild form of typing
(or have continuation variables tagged with labels):
in the renaming reduction we need to know that the continuation variable $κ$ comes
from an $\S$ with the matching label:
$$κ^\ell⟦\S^\ell κ'.\,e⟧ → e\subst{κ'}{κ}$$

One could wonder why we don't have tail-of-plug reductions, such as:
$$κ⟦L[\S κ'.\,e]⟧ → κ⟦L[A\,e\subst{κ'}{κ}]⟧$$
The reason is they won't work in the multi-prompt setting where
$κ$ is allowed to have delimiters of different labels in the middle.

With labeled operators,
the case of an $\S$ in the tail position of a mismatched delimiter is interesting.
We believe the correct rewrite is:
$$⟨L[\S^{\ell}κ.\,e]⟩^{\ell'} → ⟨L[\A^{\ell'} \S^\ell κ.\,e\subst{κ}{κ⟦⟨□⟩^{\ell'}⟧}]⟩^{\ell'}$$
It can be understood as an unrolling of the loop that searches for the correct delimiter.



\section{First-class continuations}
In our encodings of effect handlers we wrap continuations into lambdas,
therefore only values can be plugged.
We have argued against this restriction in a reduction theory,
not so much in user-facing syntax.
Still, one way to lift the restriction is to make continuations variables $κ$ values
and allow passing them as arguments to functions.
It might not be necessary,
since there's an easy workaround of representing continuations
as functions that receive a thunk.

Having first-class composable continuations
lets us question whether
the extension with labels from the previous section is really necessary.
We could potentially store labels as the values in delimiters
and ``move the loop into userspace'':
\begin{align*}
	&\keyword{letrec}\;\shiftz^\ell f = \\
	&\quad\S κ.\,\keyword{if}\;\Ask(κ)=\ell \\
	&\quad\quad\keyword{then}\;f\,κ \\
	&\quad\quad\keyword{else}\;\shiftz^\ell(λκ'.\, f\,(\keyword{compose}\:κ'\,κ))
\end{align*}
Here, $\shiftz^\ell$ is a function that passes the
continuation to the callback $f$.
More research is needed to determine
if this approach is correct and see
how well it plays with dynamically bound values, optimizations, typing rules, etc.

\section{Type-and-effect system}
A type-and-effect system for the calculus should
preserve typability when translating (as in figure \ref{shorthands})
from conventional typed calculi for algebraic effects.

%A guarantee of no unhandled effects would let us perform $\A.d$ in any context.

\section{Sheep effect handlers}
It should be clear that the central idea of this work, the tail-of-delimiter reductions,
doesn't apply to \textit{dynamic} delimited control.
These are the operators that remove the delimiter after capture,
for example \textsf{control\textsubscript{0}}:
$$⟨E[\mathsf{control_0} κ.\,e]⟩ ↦ e\subst{κ}{E}$$
The only hope for optimizations seems to be purity-aware reductions,
which could move the delimiter directly to the operator. The same applies to the related \textit{shallow} effect handlers.
There is, however, an option between shallow and deep handlers: \textit{sheep} handlers \cite{sheep},
where the delimiter is static,
but the dynamically bound interpretation of the effect can be used at most once
and has to be manually reinstated every time a continuation is installed.

\section{Downgrading delimiters}
In the process of optimization,
a delimiter might become only needed for the dynamically bound value
and not for general control.
Such a delimiter could be implemented more efficiently,
just as exception handlers are less costly than effect handlers.

\section{Tail aborts}
An $\abort$ in the tail position of a delimiter
doesn't have to search for it,
it only has to pop exactly one stack frame.
This is a potential low-level optimization that can't be expressed in our calculus.
Perhaps when control is fully statically determined,
it can be turned into jumps to join points \cite{cwc}.

\section{Specialization}
Some optimizations are program transformations that perhaps shouldn't be part of reduction.
One example is specializing functions that we know will run under a particular effect interpretation,
this is especially useful if the function is recursive.
A potential way to achieve this is
to create a copy of a function with $\Ask(κ)$ replaced with that interpretation.
%In our calculus, we can create a copy of the function with $\Ask(κ)$ replaced with that interpretation.

% the scheme by \ref{sahel, karachalias} does work (initially i thought it doesnt)
% it doesn't replace f with f' in the specialized function's body
%$$\Letrec{f\;x}{e_f}{\Handle f\,v \With x\,k.\,e_h} → \Letrec {f'\;x}{\Handle e_f \With x\,k.\,e_h}{f'\,v}$$

\section{Branching}
We have aimed for a minimal calculus that lets us showcase our ideas.
To model more realistic programming languages,
many extensions are obviously needed.
While many features (e.g.\  pairs)
could be handwaved away as adequately $λ$-encodable,
some may need more careful treatment.
One example is branching constructs such as $\keyword{case}$ expressions,
which introduce new kinds of tail contexts
and consequently our novel reductions would need generalization.

%\hfuzz=1pt
\printbibliography[heading=bibintoc]

\end{document}
